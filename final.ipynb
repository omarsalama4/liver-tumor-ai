{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1966702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omars\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading tumor slices with patient ID tracking...\n",
      "  volume_pt1/volume-0.nii: 29 tumor slices\n",
      "  volume_pt1/volume-1.nii: 29 tumor slices\n",
      "  volume_pt1/volume-10.nii: 181 tumor slices\n",
      "  volume_pt1/volume-2.nii: 139 tumor slices\n",
      "  volume_pt1/volume-3.nii: 169 tumor slices\n",
      "  volume_pt1/volume-4.nii: 250 tumor slices\n",
      "  volume_pt1/volume-5.nii: 176 tumor slices\n",
      "  volume_pt1/volume-6.nii: 186 tumor slices\n",
      "  volume_pt1/volume-7.nii: 177 tumor slices\n",
      "  volume_pt1/volume-8.nii: 179 tumor slices\n",
      "  volume_pt1/volume-9.nii: 173 tumor slices\n",
      "  volume_pt2/volume-11.nii: 167 tumor slices\n",
      "  volume_pt2/volume-12.nii: 189 tumor slices\n",
      "  volume_pt2/volume-13.nii: 142 tumor slices\n",
      "  volume_pt2/volume-14.nii: 139 tumor slices\n",
      "  volume_pt2/volume-15.nii: 133 tumor slices\n",
      "  volume_pt2/volume-16.nii: 187 tumor slices\n",
      "  volume_pt2/volume-17.nii: 198 tumor slices\n",
      "  volume_pt2/volume-18.nii: 189 tumor slices\n",
      "  volume_pt2/volume-19.nii: 188 tumor slices\n",
      "  volume_pt2/volume-20.nii: 194 tumor slices\n",
      "  volume_pt3/volume-21.nii: 175 tumor slices\n",
      "  volume_pt3/volume-22.nii: 46 tumor slices\n",
      "  volume_pt3/volume-23.nii: 116 tumor slices\n",
      "  volume_pt3/volume-24.nii: 118 tumor slices\n",
      "  volume_pt3/volume-25.nii: 232 tumor slices\n",
      "  volume_pt3/volume-26.nii: 192 tumor slices\n",
      "  volume_pt3/volume-27.nii: 229 tumor slices\n",
      "  volume_pt3/volume-28.nii: 98 tumor slices\n",
      "  volume_pt3/volume-29.nii: 114 tumor slices\n",
      "  volume_pt3/volume-30.nii: 123 tumor slices\n",
      "  volume_pt4/volume-31.nii: 67 tumor slices\n",
      "  volume_pt4/volume-32.nii: 119 tumor slices\n",
      "  volume_pt4/volume-33.nii: 96 tumor slices\n",
      "  volume_pt4/volume-34.nii: 98 tumor slices\n",
      "  volume_pt4/volume-35.nii: 116 tumor slices\n",
      "  volume_pt4/volume-36.nii: 89 tumor slices\n",
      "  volume_pt4/volume-37.nii: 99 tumor slices\n",
      "  volume_pt4/volume-38.nii: 96 tumor slices\n",
      "  volume_pt4/volume-39.nii: 239 tumor slices\n",
      "  volume_pt4/volume-40.nii: 90 tumor slices\n",
      "  volume_pt5/volume-41.nii: 104 tumor slices\n",
      "  volume_pt5/volume-42.nii: 115 tumor slices\n",
      "  volume_pt5/volume-43.nii: 113 tumor slices\n",
      "  volume_pt5/volume-44.nii: 113 tumor slices\n",
      "  volume_pt5/volume-45.nii: 59 tumor slices\n",
      "  volume_pt5/volume-46.nii: 41 tumor slices\n",
      "  volume_pt5/volume-47.nii: 85 tumor slices\n",
      "  volume_pt5/volume-48.nii: 69 tumor slices\n",
      "  volume_pt5/volume-49.nii: 73 tumor slices\n",
      "  volume_pt5/volume-50.nii: 64 tumor slices\n",
      "\n",
      "Total tumor slices: 6802 from 5 patients\n",
      "Collecting healthy slices (max 200 per patient)...\n",
      "Healthy slices added: 6579\n",
      "Total classification samples: 13381\n",
      "\n",
      "Split Summary:\n",
      "  Train patients: 4 → Cls: 11708 | Seg: 5966\n",
      "  Val   patients: 1 → Cls: 1673 | Seg: 836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==============================\n",
    "# 1. CONFIG\n",
    "# ==============================\n",
    "BASE_PATH = 'archive'\n",
    "SEG_FOLDER = os.path.join(BASE_PATH, 'segmentations')\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MAX_HEALTHY_PER_PATIENT = 200\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==============================\n",
    "# 2. UTILS\n",
    "# ==============================\n",
    "def load_nifti(path):\n",
    "    return nib.load(path).get_fdata()\n",
    "\n",
    "def normalize(volume):\n",
    "    volume = np.clip(volume, -1000, 400)\n",
    "    volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
    "    return volume.astype(np.float32)\n",
    "\n",
    "def preprocess_volume_and_mask(vol_path, seg_path):\n",
    "    vol = normalize(load_nifti(vol_path))\n",
    "    mask = load_nifti(seg_path)\n",
    "    slices = []\n",
    "    for z in range(vol.shape[2]):\n",
    "        if np.any(mask[:, :, z]):  # tumor present\n",
    "            img = resize(vol[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "            msk = resize(mask[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "            msk = (msk > 0.5).astype(np.uint8)\n",
    "            slices.append((img, msk))\n",
    "    return slices\n",
    "\n",
    "# ==============================\n",
    "# 3. LOAD DATA WITH PATIENT TRACKING\n",
    "# ==============================\n",
    "print(\"Loading tumor slices with patient ID tracking...\")\n",
    "volume_folders = [f for f in os.listdir(BASE_PATH) if f.startswith(\"volume_pt\")]\n",
    "all_slices_with_patient = []  # (img, mask, patient_id)\n",
    "\n",
    "for patient_folder in volume_folders:\n",
    "    patient_id = patient_folder\n",
    "    patient_path = os.path.join(BASE_PATH, patient_folder)\n",
    "    for file in os.listdir(patient_path):\n",
    "        if file.startswith(\"volume\") and file.endswith(\".nii\"):\n",
    "            vol_path = os.path.join(patient_path, file)\n",
    "            seg_path = os.path.join(SEG_FOLDER, file.replace(\"volume\", \"segmentation\"))\n",
    "            if os.path.exists(seg_path):\n",
    "                slices = preprocess_volume_and_mask(vol_path, seg_path)\n",
    "                for img, mask in slices:\n",
    "                    all_slices_with_patient.append((img, mask, patient_id))\n",
    "                print(f\"  {patient_id}/{file}: {len(slices)} tumor slices\")\n",
    "\n",
    "print(f\"\\nTotal tumor slices: {len(all_slices_with_patient)} from {len(volume_folders)} patients\")\n",
    "\n",
    "# ==============================\n",
    "# 4. BUILD CLASSIFICATION DATASET\n",
    "# ==============================\n",
    "labeled_data = []\n",
    "# Tumor slices → label 1\n",
    "for img, mask, pid in all_slices_with_patient:\n",
    "    labeled_data.append((img, 1, pid))\n",
    "\n",
    "# Healthy slices → label 0\n",
    "print(\"Collecting healthy slices (max 200 per patient)...\")\n",
    "healthy_per_patient = {}\n",
    "for patient_folder in volume_folders:\n",
    "    patient_id = patient_folder\n",
    "    patient_path = os.path.join(BASE_PATH, patient_folder)\n",
    "    for file in os.listdir(patient_path):\n",
    "        if file.startswith(\"volume\") and file.endswith(\".nii\"):\n",
    "            vol_path = os.path.join(patient_path, file)\n",
    "            seg_path = os.path.join(SEG_FOLDER, file.replace(\"volume\", \"segmentation\"))\n",
    "            if not os.path.exists(seg_path):\n",
    "                continue\n",
    "            vol = normalize(load_nifti(vol_path))\n",
    "            mask = load_nifti(seg_path)\n",
    "            count = 0\n",
    "            for z in range(vol.shape[2]):\n",
    "                if count >= MAX_HEALTHY_PER_PATIENT:\n",
    "                    break\n",
    "                if np.sum(mask[:, :, z]) == 0:\n",
    "                    img = resize(vol[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "                    healthy_per_patient.setdefault(patient_id, []).append(img)\n",
    "                    count += 1\n",
    "\n",
    "for pid, imgs in healthy_per_patient.items():\n",
    "    for img in imgs:\n",
    "        labeled_data.append((img, 0, pid))\n",
    "\n",
    "print(f\"Healthy slices added: {len(labeled_data) - len(all_slices_with_patient)}\")\n",
    "print(f\"Total classification samples: {len(labeled_data)}\")\n",
    "\n",
    "# ==============================\n",
    "# 5. PATIENT-LEVEL SPLIT (ZERO LEAKAGE)\n",
    "# ==============================\n",
    "all_patients = list({pid for _, _, pid in labeled_data})\n",
    "train_patients, val_patients = train_test_split(all_patients, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Classification split\n",
    "train_cls = [(img, label) for img, label, pid in labeled_data if pid in train_patients]\n",
    "val_cls   = [(img, label) for img, label, pid in labeled_data if pid in val_patients]\n",
    "\n",
    "# Segmentation split (only tumor slices)\n",
    "train_seg = [(img, mask) for img, mask, pid in all_slices_with_patient if pid in train_patients]\n",
    "val_seg   = [(img, mask) for img, mask, pid in all_slices_with_patient if pid in val_patients]\n",
    "\n",
    "print(f\"\\nSplit Summary:\")\n",
    "print(f\"  Train patients: {len(train_patients)} → Cls: {len(train_cls)} | Seg: {len(train_seg)}\")\n",
    "print(f\"  Val   patients: {len(val_patients)} → Cls: {len(val_cls)} | Seg: {len(val_seg)}\")\n",
    "\n",
    "# ==============================\n",
    "# 6. DATASETS\n",
    "# ==============================\n",
    "class TumorClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.data[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Loaders\n",
    "cls_train_loader = DataLoader(TumorClassificationDataset(train_cls), batch_size=32, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "cls_val_loader   = DataLoader(TumorClassificationDataset(val_cls),   batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "seg_train_loader = DataLoader(SegmentationDataset(train_seg), batch_size=8,  shuffle=True,  num_workers=0, pin_memory=True)\n",
    "seg_val_loader   = DataLoader(SegmentationDataset(val_seg),   batch_size=8,  shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ca892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "======================================================================\n",
      "FINAL TRAINING – Patient-Independent, No Leakage, Real Metrics\n",
      "======================================================================\n",
      "Epoch  1 | Cls: 0.9455 → 0.7932 | Seg: 0.1826 → 0.1076 | Dice: 0.8840\n",
      "  New best! Val Acc: 0.7932 | Dice: 0.8840\n",
      "Epoch  2 | Cls: 0.9830 → 0.8368 | Seg: 0.0332 → 0.0839 | Dice: 0.8890\n",
      "  New best! Val Acc: 0.8368 | Dice: 0.8890\n",
      "Epoch  3 | Cls: 0.9851 → 0.8057 | Seg: 0.0228 → 0.0713 | Dice: 0.9043\n",
      "Epoch  4 | Cls: 0.9902 → 0.8237 | Seg: 0.0188 → 0.0656 | Dice: 0.9100\n",
      "Epoch  5 | Cls: 0.9903 → 0.7878 | Seg: 0.0165 → 0.0621 | Dice: 0.9138\n",
      "Epoch  6 | Cls: 0.9914 → 0.8159 | Seg: 0.0156 → 0.0669 | Dice: 0.9049\n",
      "Epoch  7 | Cls: 0.9917 → 0.8159 | Seg: 0.0142 → 0.0630 | Dice: 0.9112\n",
      "Epoch  8 | Cls: 0.9932 → 0.8189 | Seg: 0.0130 → 0.0610 | Dice: 0.9156\n",
      "Epoch  9 | Cls: 0.9925 → 0.8117 | Seg: 0.0122 → 0.0647 | Dice: 0.9101\n",
      "Epoch 10 | Cls: 0.9927 → 0.7890 | Seg: 0.0119 → 0.0640 | Dice: 0.9123\n",
      "Epoch 11 | Cls: 0.9947 → 0.8273 | Seg: 0.0112 → 0.0649 | Dice: 0.9127\n",
      "Epoch 12 | Cls: 0.9933 → 0.7681 | Seg: 0.0106 → 0.0611 | Dice: 0.9167\n",
      "Epoch 13 | Cls: 0.9947 → 0.8129 | Seg: 0.0104 → 0.0627 | Dice: 0.9121\n",
      "Epoch 14 | Cls: 0.9952 → 0.7286 | Seg: 0.0099 → 0.0659 | Dice: 0.9089\n",
      "Epoch 15 | Cls: 0.9961 → 0.7890 | Seg: 0.0095 → 0.0646 | Dice: 0.9118\n",
      "Epoch 16 | Cls: 0.9944 → 0.8027 | Seg: 0.0094 → 0.0632 | Dice: 0.9130\n",
      "Epoch 17 | Cls: 0.9953 → 0.8207 | Seg: 0.0089 → 0.0663 | Dice: 0.9092\n",
      "Early stopping!\n",
      "\n",
      "Training complete! Best validation accuracy: 0.8368\n",
      "Model saved as 'best_brain_tumor_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. CLASSIFICATION AUGMENTATION (Fixed: Add Normalize!)\n",
    "# ============================================================\n",
    "cls_train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(var_limit=(5, 30), p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=25, p=0.6),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.4),\n",
    "    A.Normalize(mean=0.5, std=0.5),        # ← CRITICAL: was missing!\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "cls_val_transform = A.Compose([\n",
    "    A.Normalize(mean=0.5, std=0.5),        # ← Also needed here!\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 2. CLASSIFICATION MODEL (Fixed: logits output + BN)\n",
    "# ============================================================\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(                    # ← Added extra layer\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, 1)                           # ← Raw logits (no sigmoid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x).squeeze(1)                    # ← Return logits\n",
    "\n",
    "# Use BCEWithLogitsLoss → more stable\n",
    "cls_model = SimpleCNN().to(device)\n",
    "cls_criterion = nn.BCEWithLogitsLoss()              # ← Changed!\n",
    "cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# ============================================================\n",
    "# 3. SEGMENTATION MODEL (Fixed: pretrained + no activation)\n",
    "# ============================================================\n",
    "seg_model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",        # ← Use pretrained! Huge boost\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation=None,                   # ← Critical: output logits\n",
    "    decoder_attention_type=\"scse\"      # ← Bonus: better attention\n",
    ").to(device)\n",
    "\n",
    "dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def seg_criterion(pred, target):\n",
    "    return 0.7 * dice_loss(pred, target) + 0.3 * bce_loss(pred, target)  # ← Weighted\n",
    "\n",
    "seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# small helper: Dice score implementation (fix NameError: dice not defined)\n",
    "def dice(pred, target, eps=1e-6, average='micro'):\n",
    "    \"\"\"\n",
    "    Compute Dice coefficient between pred and target.\n",
    "    Supports per-sample batches or single 2D masks.\n",
    "    pred: Tensor, binary (0/1) or probabilities (will be cast to float)\n",
    "    target: Tensor, binary (0/1)\n",
    "    average: 'micro' returns a single scalar; 'none' returns per-sample scores.\n",
    "    \"\"\"\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "\n",
    "    # single mask [H, W]\n",
    "    if pred.dim() == 2 and target.dim() == 2:\n",
    "        inter = (pred * target).sum()\n",
    "        denom = pred.sum() + target.sum()\n",
    "        return (2.0 * inter + eps) / (denom + eps)\n",
    "\n",
    "    # assume batch dimension first: [B, ...]\n",
    "    pred_flat = pred.view(pred.size(0), -1)\n",
    "    target_flat = target.view(target.size(0), -1)\n",
    "    inter = (pred_flat * target_flat).sum(dim=1)\n",
    "    denom = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
    "    scores = (2.0 * inter + eps) / (denom + eps)\n",
    "\n",
    "    if average == 'micro':\n",
    "        return scores.mean()\n",
    "    elif average == 'none':\n",
    "        return scores\n",
    "    else:\n",
    "        return scores.mean()\n",
    "\n",
    "# ============================================================\n",
    "# 4. TRAINING FUNCTIONS (Fixed accuracy calculation)\n",
    "# ============================================================\n",
    "def train_cls_epoch():\n",
    "    cls_model.train()\n",
    "    total_loss = correct = total = 0\n",
    "    for x, y in cls_train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = cls_model(x)\n",
    "        loss = cls_criterion(logits, y)\n",
    "        \n",
    "        cls_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cls_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = torch.sigmoid(logits) > 0.5\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return total_loss / len(cls_train_loader), correct / total\n",
    "\n",
    "def val_cls_epoch():\n",
    "    cls_model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in cls_val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = cls_model(x)\n",
    "            pred = torch.sigmoid(logits) > 0.5\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def train_seg_epoch():\n",
    "    seg_model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in seg_train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = seg_model(x)\n",
    "        loss = seg_criterion(pred, y)\n",
    "        \n",
    "        seg_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        seg_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(seg_train_loader)\n",
    "\n",
    "def val_seg_epoch():\n",
    "    seg_model.eval()\n",
    "    total_loss = 0\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in seg_val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = seg_model(x)\n",
    "            loss = seg_criterion(pred, y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "            # ensure target is float/binary for dice()\n",
    "            dice_scores.append(dice(pred_bin, y.float(), average='micro').item())\n",
    "    \n",
    "    return total_loss / len(seg_val_loader), np.mean(dice_scores)\n",
    "\n",
    "# ============================================================\n",
    "# 5. TRAIN LOOP + EARLY STOPPING + REAL DICE\n",
    "# ============================================================\n",
    "best_val_acc = 0.0\n",
    "patience = 15\n",
    "counter = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAINING – Patient-Independent, No Leakage, Real Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    cls_train_loss, cls_train_acc = train_cls_epoch()\n",
    "    cls_val_acc = val_cls_epoch()\n",
    "    seg_train_loss = train_seg_epoch()\n",
    "    seg_val_loss, seg_val_dice = val_seg_epoch()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Cls: {cls_train_acc:.4f} → {cls_val_acc:.4f} | \"\n",
    "          f\"Seg: {seg_train_loss:.4f} → {seg_val_loss:.4f} | \"\n",
    "          f\"Dice: {seg_val_dice:.4f}\")\n",
    "    \n",
    "    # Save best\n",
    "    if cls_val_acc > best_val_acc:\n",
    "        best_val_acc = cls_val_acc\n",
    "        torch.save({\n",
    "            'cls_model': cls_model.state_dict(),\n",
    "            'seg_model': seg_model.state_dict(),\n",
    "            'cls_acc': cls_val_acc,\n",
    "            'epoch': epoch\n",
    "        }, \"best_brain_tumor_model.pth\")\n",
    "        print(f\"  New best! Val Acc: {best_val_acc:.4f} | Dice: {seg_val_dice:.4f}\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTraining complete! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(\"Model saved as 'best_brain_tumor_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "358cd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_brain_tumor_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6761cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['seg_model'] = seg_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada6396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, \"best_liver_tumor_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
