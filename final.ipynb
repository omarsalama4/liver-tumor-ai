{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c5cd91",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59967c",
   "metadata": {},
   "source": [
    "## 1. CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072fa0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omars\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_PATH = 'archive'\n",
    "SEG_FOLDER = os.path.join(BASE_PATH, 'segmentations')\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MAX_HEALTHY_PER_PATIENT = 200\n",
    "SEED = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9224611",
   "metadata": {},
   "source": [
    "## 2. UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d931f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(path):\n",
    "    return nib.load(path).get_fdata()\n",
    "\n",
    "def normalize(volume):\n",
    "    volume = np.clip(volume, -1000, 400)\n",
    "    volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
    "    return volume.astype(np.float32)\n",
    "\n",
    "def preprocess_volume_and_mask(vol_path, seg_path):\n",
    "    vol = normalize(load_nifti(vol_path))\n",
    "    mask = load_nifti(seg_path)\n",
    "    slices = []\n",
    "    for z in range(vol.shape[2]):\n",
    "        if np.any(mask[:, :, z]):  # tumor present\n",
    "            img = resize(vol[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "            msk = resize(mask[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "            msk = (msk > 0.5).astype(np.uint8)\n",
    "            slices.append((img, msk))\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6517ad1",
   "metadata": {},
   "source": [
    "## 3. LOAD DATA WITH PATIENT TRACKING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b46590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tumor slices with patient ID tracking...\n",
      "  volume_pt1/volume-0.nii: 29 tumor slices\n",
      "  volume_pt1/volume-1.nii: 29 tumor slices\n",
      "  volume_pt1/volume-10.nii: 181 tumor slices\n",
      "  volume_pt1/volume-2.nii: 139 tumor slices\n",
      "  volume_pt1/volume-3.nii: 169 tumor slices\n",
      "  volume_pt1/volume-4.nii: 250 tumor slices\n",
      "  volume_pt1/volume-5.nii: 176 tumor slices\n",
      "  volume_pt1/volume-6.nii: 186 tumor slices\n",
      "  volume_pt1/volume-7.nii: 177 tumor slices\n",
      "  volume_pt1/volume-8.nii: 179 tumor slices\n",
      "  volume_pt1/volume-9.nii: 173 tumor slices\n",
      "  volume_pt2/volume-11.nii: 167 tumor slices\n",
      "  volume_pt2/volume-12.nii: 189 tumor slices\n",
      "  volume_pt2/volume-13.nii: 142 tumor slices\n",
      "  volume_pt2/volume-14.nii: 139 tumor slices\n",
      "  volume_pt2/volume-15.nii: 133 tumor slices\n",
      "  volume_pt2/volume-16.nii: 187 tumor slices\n",
      "  volume_pt2/volume-17.nii: 198 tumor slices\n",
      "  volume_pt2/volume-18.nii: 189 tumor slices\n",
      "  volume_pt2/volume-19.nii: 188 tumor slices\n",
      "  volume_pt2/volume-20.nii: 194 tumor slices\n",
      "  volume_pt3/volume-21.nii: 175 tumor slices\n",
      "  volume_pt3/volume-22.nii: 46 tumor slices\n",
      "  volume_pt3/volume-23.nii: 116 tumor slices\n",
      "  volume_pt3/volume-24.nii: 118 tumor slices\n",
      "  volume_pt3/volume-25.nii: 232 tumor slices\n",
      "  volume_pt3/volume-26.nii: 192 tumor slices\n",
      "  volume_pt3/volume-27.nii: 229 tumor slices\n",
      "  volume_pt3/volume-28.nii: 98 tumor slices\n",
      "  volume_pt3/volume-29.nii: 114 tumor slices\n",
      "  volume_pt3/volume-30.nii: 123 tumor slices\n",
      "  volume_pt4/volume-31.nii: 67 tumor slices\n",
      "  volume_pt4/volume-32.nii: 119 tumor slices\n",
      "  volume_pt4/volume-33.nii: 96 tumor slices\n",
      "  volume_pt4/volume-34.nii: 98 tumor slices\n",
      "  volume_pt4/volume-35.nii: 116 tumor slices\n",
      "  volume_pt4/volume-36.nii: 89 tumor slices\n",
      "  volume_pt4/volume-37.nii: 99 tumor slices\n",
      "  volume_pt4/volume-38.nii: 96 tumor slices\n",
      "  volume_pt4/volume-39.nii: 239 tumor slices\n",
      "  volume_pt4/volume-40.nii: 90 tumor slices\n",
      "  volume_pt5/volume-41.nii: 104 tumor slices\n",
      "  volume_pt5/volume-42.nii: 115 tumor slices\n",
      "  volume_pt5/volume-43.nii: 113 tumor slices\n",
      "  volume_pt5/volume-44.nii: 113 tumor slices\n",
      "  volume_pt5/volume-45.nii: 59 tumor slices\n",
      "  volume_pt5/volume-46.nii: 41 tumor slices\n",
      "  volume_pt5/volume-47.nii: 85 tumor slices\n",
      "  volume_pt5/volume-48.nii: 69 tumor slices\n",
      "  volume_pt5/volume-49.nii: 73 tumor slices\n",
      "  volume_pt5/volume-50.nii: 64 tumor slices\n",
      "  volume_pt6/volume-100.nii: 276 tumor slices\n",
      "  volume_pt6/volume-51.nii: 56 tumor slices\n",
      "  volume_pt6/volume-52.nii: 56 tumor slices\n",
      "  volume_pt6/volume-53.nii: 44 tumor slices\n",
      "  volume_pt6/volume-54.nii: 29 tumor slices\n",
      "  volume_pt6/volume-55.nii: 92 tumor slices\n",
      "  volume_pt6/volume-56.nii: 91 tumor slices\n",
      "  volume_pt6/volume-57.nii: 149 tumor slices\n",
      "  volume_pt6/volume-58.nii: 83 tumor slices\n",
      "  volume_pt6/volume-59.nii: 77 tumor slices\n",
      "  volume_pt6/volume-60.nii: 79 tumor slices\n",
      "  volume_pt6/volume-61.nii: 61 tumor slices\n",
      "  volume_pt6/volume-62.nii: 89 tumor slices\n",
      "  volume_pt6/volume-63.nii: 37 tumor slices\n",
      "  volume_pt6/volume-64.nii: 104 tumor slices\n",
      "  volume_pt6/volume-65.nii: 201 tumor slices\n",
      "  volume_pt6/volume-66.nii: 36 tumor slices\n",
      "  volume_pt6/volume-67.nii: 79 tumor slices\n",
      "  volume_pt6/volume-68.nii: 64 tumor slices\n",
      "  volume_pt6/volume-69.nii: 96 tumor slices\n",
      "  volume_pt6/volume-70.nii: 110 tumor slices\n",
      "  volume_pt6/volume-71.nii: 36 tumor slices\n",
      "  volume_pt6/volume-72.nii: 58 tumor slices\n",
      "  volume_pt6/volume-73.nii: 50 tumor slices\n",
      "  volume_pt6/volume-74.nii: 32 tumor slices\n",
      "  volume_pt6/volume-75.nii: 37 tumor slices\n",
      "  volume_pt6/volume-76.nii: 75 tumor slices\n",
      "  volume_pt6/volume-77.nii: 36 tumor slices\n",
      "  volume_pt6/volume-78.nii: 59 tumor slices\n",
      "  volume_pt6/volume-79.nii: 59 tumor slices\n",
      "  volume_pt6/volume-80.nii: 76 tumor slices\n",
      "  volume_pt6/volume-81.nii: 111 tumor slices\n",
      "  volume_pt6/volume-82.nii: 170 tumor slices\n",
      "  volume_pt6/volume-83.nii: 215 tumor slices\n",
      "  volume_pt6/volume-84.nii: 258 tumor slices\n",
      "  volume_pt6/volume-85.nii: 276 tumor slices\n",
      "  volume_pt6/volume-86.nii: 280 tumor slices\n",
      "  volume_pt6/volume-87.nii: 215 tumor slices\n",
      "  volume_pt6/volume-88.nii: 175 tumor slices\n",
      "  volume_pt6/volume-89.nii: 193 tumor slices\n",
      "  volume_pt6/volume-90.nii: 183 tumor slices\n",
      "  volume_pt6/volume-91.nii: 189 tumor slices\n",
      "  volume_pt6/volume-92.nii: 179 tumor slices\n",
      "  volume_pt6/volume-93.nii: 234 tumor slices\n",
      "  volume_pt6/volume-94.nii: 251 tumor slices\n",
      "  volume_pt6/volume-95.nii: 263 tumor slices\n",
      "  volume_pt6/volume-96.nii: 299 tumor slices\n",
      "  volume_pt6/volume-97.nii: 232 tumor slices\n",
      "  volume_pt6/volume-98.nii: 241 tumor slices\n",
      "  volume_pt6/volume-99.nii: 226 tumor slices\n",
      "  volume_pt8/volume-101.nii: 259 tumor slices\n",
      "  volume_pt8/volume-102.nii: 266 tumor slices\n",
      "  volume_pt8/volume-103.nii: 214 tumor slices\n",
      "  volume_pt8/volume-104.nii: 194 tumor slices\n",
      "  volume_pt8/volume-105.nii: 239 tumor slices\n",
      "  volume_pt8/volume-106.nii: 168 tumor slices\n",
      "  volume_pt8/volume-107.nii: 248 tumor slices\n",
      "  volume_pt8/volume-108.nii: 205 tumor slices\n",
      "  volume_pt8/volume-109.nii: 194 tumor slices\n",
      "  volume_pt8/volume-110.nii: 189 tumor slices\n",
      "  volume_pt8/volume-111.nii: 233 tumor slices\n",
      "  volume_pt8/volume-112.nii: 191 tumor slices\n",
      "  volume_pt8/volume-113.nii: 170 tumor slices\n",
      "  volume_pt8/volume-114.nii: 215 tumor slices\n",
      "  volume_pt8/volume-115.nii: 186 tumor slices\n",
      "  volume_pt8/volume-116.nii: 219 tumor slices\n",
      "  volume_pt8/volume-117.nii: 260 tumor slices\n",
      "  volume_pt8/volume-118.nii: 122 tumor slices\n",
      "  volume_pt8/volume-119.nii: 132 tumor slices\n",
      "  volume_pt8/volume-120.nii: 120 tumor slices\n",
      "  volume_pt8/volume-121.nii: 113 tumor slices\n",
      "  volume_pt8/volume-122.nii: 118 tumor slices\n",
      "  volume_pt8/volume-123.nii: 115 tumor slices\n",
      "  volume_pt8/volume-124.nii: 112 tumor slices\n",
      "  volume_pt8/volume-125.nii: 112 tumor slices\n",
      "  volume_pt8/volume-126.nii: 113 tumor slices\n",
      "  volume_pt8/volume-127.nii: 227 tumor slices\n",
      "  volume_pt8/volume-128.nii: 292 tumor slices\n",
      "  volume_pt8/volume-129.nii: 277 tumor slices\n",
      "  volume_pt8/volume-130.nii: 241 tumor slices\n",
      "\n",
      "Total tumor slices: 19163 from 7 patients\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tumor slices with patient ID tracking...\")\n",
    "volume_folders = [f for f in os.listdir(BASE_PATH) if f.startswith(\"volume_pt\")]\n",
    "all_slices_with_patient = []  # (img, mask, patient_id)\n",
    "\n",
    "for patient_folder in volume_folders:\n",
    "    patient_id = patient_folder\n",
    "    patient_path = os.path.join(BASE_PATH, patient_folder)\n",
    "    for file in os.listdir(patient_path):\n",
    "        if file.startswith(\"volume\") and file.endswith(\".nii\"):\n",
    "            vol_path = os.path.join(patient_path, file)\n",
    "            seg_path = os.path.join(SEG_FOLDER, file.replace(\"volume\", \"segmentation\"))\n",
    "            if os.path.exists(seg_path):\n",
    "                slices = preprocess_volume_and_mask(vol_path, seg_path)\n",
    "                for img, mask in slices:\n",
    "                    all_slices_with_patient.append((img, mask, patient_id))\n",
    "                print(f\"  {patient_id}/{file}: {len(slices)} tumor slices\")\n",
    "\n",
    "print(f\"\\nTotal tumor slices: {len(all_slices_with_patient)} from {len(volume_folders)} patients\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e336c96",
   "metadata": {},
   "source": [
    "## 4. BUILD CLASSIFICATION DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced13b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting healthy slices (max 200 per patient)...\n",
      "Healthy slices added: 19920\n",
      "Total classification samples: 39083\n"
     ]
    }
   ],
   "source": [
    "labeled_data = []\n",
    "# Tumor slices → label 1\n",
    "for img, mask, pid in all_slices_with_patient:\n",
    "    labeled_data.append((img, 1, pid))\n",
    "\n",
    "# Healthy slices → label 0\n",
    "print(\"Collecting healthy slices (max 200 per patient)...\")\n",
    "healthy_per_patient = {}\n",
    "for patient_folder in volume_folders:\n",
    "    patient_id = patient_folder\n",
    "    patient_path = os.path.join(BASE_PATH, patient_folder)\n",
    "    for file in os.listdir(patient_path):\n",
    "        if file.startswith(\"volume\") and file.endswith(\".nii\"):\n",
    "            vol_path = os.path.join(patient_path, file)\n",
    "            seg_path = os.path.join(SEG_FOLDER, file.replace(\"volume\", \"segmentation\"))\n",
    "            if not os.path.exists(seg_path):\n",
    "                continue\n",
    "            vol = normalize(load_nifti(vol_path))\n",
    "            mask = load_nifti(seg_path)\n",
    "            count = 0\n",
    "            for z in range(vol.shape[2]):\n",
    "                if count >= MAX_HEALTHY_PER_PATIENT:\n",
    "                    break\n",
    "                if np.sum(mask[:, :, z]) == 0:\n",
    "                    img = resize(vol[:, :, z], IMAGE_SIZE, preserve_range=True)\n",
    "                    healthy_per_patient.setdefault(patient_id, []).append(img)\n",
    "                    count += 1\n",
    "\n",
    "for pid, imgs in healthy_per_patient.items():\n",
    "    for img in imgs:\n",
    "        labeled_data.append((img, 0, pid))\n",
    "\n",
    "print(f\"Healthy slices added: {len(labeled_data) - len(all_slices_with_patient)}\")\n",
    "print(f\"Total classification samples: {len(labeled_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3b23b",
   "metadata": {},
   "source": [
    "## 5. PATIENT-LEVEL SPLIT (ZERO LEAKAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fd4e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split Summary:\n",
      "  Train patients: 5 → Cls: 25805 | Seg: 12583\n",
      "  Val   patients: 2 → Cls: 13278 | Seg: 6580\n"
     ]
    }
   ],
   "source": [
    "all_patients = list({pid for _, _, pid in labeled_data})\n",
    "train_patients, val_patients = train_test_split(all_patients, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Classification split\n",
    "train_cls = [(img, label) for img, label, pid in labeled_data if pid in train_patients]\n",
    "val_cls   = [(img, label) for img, label, pid in labeled_data if pid in val_patients]\n",
    "\n",
    "# Segmentation split (only tumor slices)\n",
    "train_seg = [(img, mask) for img, mask, pid in all_slices_with_patient if pid in train_patients]\n",
    "val_seg   = [(img, mask) for img, mask, pid in all_slices_with_patient if pid in val_patients]\n",
    "\n",
    "print(f\"\\nSplit Summary:\")\n",
    "print(f\"  Train patients: {len(train_patients)} → Cls: {len(train_cls)} | Seg: {len(train_seg)}\")\n",
    "print(f\"  Val   patients: {len(val_patients)} → Cls: {len(val_cls)} | Seg: {len(val_seg)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdf552",
   "metadata": {},
   "source": [
    "## 6. DATASETS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1966702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.data[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Loaders\n",
    "cls_train_loader = DataLoader(TumorClassificationDataset(train_cls), batch_size=32, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "cls_val_loader   = DataLoader(TumorClassificationDataset(val_cls),   batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "seg_train_loader = DataLoader(SegmentationDataset(train_seg), batch_size=8,  shuffle=True,  num_workers=0, pin_memory=True)\n",
    "seg_val_loader   = DataLoader(SegmentationDataset(val_seg),   batch_size=8,  shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57990896",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80173f",
   "metadata": {},
   "source": [
    "## 1. CLASSIFICATION AUGMENTATION (Fixed: Add Normalize!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a2793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(var_limit=(5, 30), p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=25, p=0.6),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.4),\n",
    "    A.Normalize(mean=0.5, std=0.5),        # ← CRITICAL: was missing!\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "cls_val_transform = A.Compose([\n",
    "    A.Normalize(mean=0.5, std=0.5),        # ← Also needed here!\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9f494",
   "metadata": {},
   "source": [
    "## 2. CLASSIFICATION MODEL (Fixed: logits output + BN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d231aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(                    # ← Added extra layer\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, 1)                           # ← Raw logits (no sigmoid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x).squeeze(1)                    # ← Return logits\n",
    "\n",
    "# Use BCEWithLogitsLoss → more stable\n",
    "cls_model = SimpleCNN().to(device)\n",
    "cls_criterion = nn.BCEWithLogitsLoss()              # ← Changed!\n",
    "cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3d43c",
   "metadata": {},
   "source": [
    "## 3. SEGMENTATION MODEL (Fixed: pretrained + no activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d412f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",        # ← Use pretrained! Huge boost\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation=None,                   # ← Critical: output logits\n",
    "    decoder_attention_type=\"scse\"      # ← Bonus: better attention\n",
    ").to(device)\n",
    "\n",
    "dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def seg_criterion(pred, target):\n",
    "    return 0.7 * dice_loss(pred, target) + 0.3 * bce_loss(pred, target)  # ← Weighted\n",
    "\n",
    "seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# small helper: Dice score implementation (fix NameError: dice not defined)\n",
    "def dice(pred, target, eps=1e-6, average='micro'):\n",
    "    \"\"\"\n",
    "    Compute Dice coefficient between pred and target.\n",
    "    Supports per-sample batches or single 2D masks.\n",
    "    pred: Tensor, binary (0/1) or probabilities (will be cast to float)\n",
    "    target: Tensor, binary (0/1)\n",
    "    average: 'micro' returns a single scalar; 'none' returns per-sample scores.\n",
    "    \"\"\"\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "\n",
    "    # single mask [H, W]\n",
    "    if pred.dim() == 2 and target.dim() == 2:\n",
    "        inter = (pred * target).sum()\n",
    "        denom = pred.sum() + target.sum()\n",
    "        return (2.0 * inter + eps) / (denom + eps)\n",
    "\n",
    "    # assume batch dimension first: [B, ...]\n",
    "    pred_flat = pred.view(pred.size(0), -1)\n",
    "    target_flat = target.view(target.size(0), -1)\n",
    "    inter = (pred_flat * target_flat).sum(dim=1)\n",
    "    denom = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
    "    scores = (2.0 * inter + eps) / (denom + eps)\n",
    "\n",
    "    if average == 'micro':\n",
    "        return scores.mean()\n",
    "    elif average == 'none':\n",
    "        return scores\n",
    "    else:\n",
    "        return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161474c4",
   "metadata": {},
   "source": [
    "## 4. TRAINING FUNCTIONS (Fixed accuracy calculation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0c6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cls_epoch():\n",
    "    cls_model.train()\n",
    "    total_loss = correct = total = 0\n",
    "    for x, y in cls_train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = cls_model(x)\n",
    "        loss = cls_criterion(logits, y)\n",
    "        \n",
    "        cls_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cls_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = torch.sigmoid(logits) > 0.5\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return total_loss / len(cls_train_loader), correct / total\n",
    "\n",
    "def val_cls_epoch():\n",
    "    cls_model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in cls_val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = cls_model(x)\n",
    "            pred = torch.sigmoid(logits) > 0.5\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def train_seg_epoch():\n",
    "    seg_model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in seg_train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = seg_model(x)\n",
    "        loss = seg_criterion(pred, y)\n",
    "        \n",
    "        seg_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        seg_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(seg_train_loader)\n",
    "\n",
    "def val_seg_epoch():\n",
    "    seg_model.eval()\n",
    "    total_loss = 0\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in seg_val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = seg_model(x)\n",
    "            loss = seg_criterion(pred, y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "            # ensure target is float/binary for dice()\n",
    "            dice_scores.append(dice(pred_bin, y.float(), average='micro').item())\n",
    "    \n",
    "    return total_loss / len(seg_val_loader), np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ca7f9",
   "metadata": {},
   "source": [
    "## 5. TRAIN LOOP + EARLY STOPPING + REAL DICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a49fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAINING – Patient-Independent, No Leakage, Real Metrics\n",
      "======================================================================\n",
      "Epoch  1 | Cls: 0.9470 → 0.9099 | Seg: 0.1671 → 0.0886 | Dice: 0.8979\n",
      "  New best classification! Val Acc: 0.9099\n",
      "  New best segmentation! Val Loss: 0.0886 | Dice: 0.8979\n",
      "Epoch  2 | Cls: 0.9781 → 0.9243 | Seg: 0.0314 → 0.0674 | Dice: 0.9092\n",
      "  New best classification! Val Acc: 0.9243\n",
      "  New best segmentation! Val Loss: 0.0674 | Dice: 0.9092\n",
      "Epoch  3 | Cls: 0.9826 → 0.9354 | Seg: 0.0234 → 0.0659 | Dice: 0.9064\n",
      "  New best classification! Val Acc: 0.9354\n",
      "  New best segmentation! Val Loss: 0.0659 | Dice: 0.9064\n",
      "Epoch  4 | Cls: 0.9859 → 0.9350 | Seg: 0.0198 → 0.0783 | Dice: 0.8917\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch  5 | Cls: 0.9875 → 0.9302 | Seg: 0.0178 → 0.0695 | Dice: 0.9048\n",
      "  No improvement. Counter = 2/15\n",
      "Epoch  6 | Cls: 0.9892 → 0.9363 | Seg: 0.0181 → 0.0684 | Dice: 0.9055\n",
      "  New best classification! Val Acc: 0.9363\n",
      "Epoch  7 | Cls: 0.9906 → 0.9382 | Seg: 0.0151 → 0.0711 | Dice: 0.9031\n",
      "  New best classification! Val Acc: 0.9382\n",
      "Epoch  8 | Cls: 0.9917 → 0.9422 | Seg: 0.0147 → 0.0618 | Dice: 0.9168\n",
      "  New best classification! Val Acc: 0.9422\n",
      "  New best segmentation! Val Loss: 0.0618 | Dice: 0.9168\n",
      "Epoch  9 | Cls: 0.9923 → 0.9416 | Seg: 0.0131 → 0.0668 | Dice: 0.9077\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 10 | Cls: 0.9928 → 0.9421 | Seg: 0.0139 → 0.0597 | Dice: 0.9179\n",
      "  New best segmentation! Val Loss: 0.0597 | Dice: 0.9179\n",
      "Epoch 11 | Cls: 0.9926 → 0.9435 | Seg: 0.0126 → 0.0608 | Dice: 0.9178\n",
      "  New best classification! Val Acc: 0.9435\n",
      "Epoch 12 | Cls: 0.9922 → 0.9395 | Seg: 0.0114 → 0.0612 | Dice: 0.9169\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 13 | Cls: 0.9936 → 0.9401 | Seg: 0.0110 → 0.0619 | Dice: 0.9167\n",
      "  No improvement. Counter = 2/15\n",
      "Epoch 14 | Cls: 0.9941 → 0.9335 | Seg: 0.0109 → 0.0626 | Dice: 0.9168\n",
      "  No improvement. Counter = 3/15\n",
      "Epoch 15 | Cls: 0.9937 → 0.9315 | Seg: 0.0102 → 0.0620 | Dice: 0.9179\n",
      "  No improvement. Counter = 4/15\n",
      "Epoch 16 | Cls: 0.9946 → 0.9404 | Seg: 0.0100 → 0.0745 | Dice: 0.8995\n",
      "  No improvement. Counter = 5/15\n",
      "Epoch 17 | Cls: 0.9947 → 0.9382 | Seg: 0.0096 → 0.0629 | Dice: 0.9166\n",
      "  No improvement. Counter = 6/15\n",
      "Epoch 18 | Cls: 0.9953 → 0.9446 | Seg: 0.0110 → 0.0637 | Dice: 0.9148\n",
      "  New best classification! Val Acc: 0.9446\n",
      "Epoch 19 | Cls: 0.9952 → 0.9438 | Seg: 0.0091 → 0.0651 | Dice: 0.9139\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 20 | Cls: 0.9957 → 0.9346 | Seg: 0.0086 → 0.0659 | Dice: 0.9123\n",
      "  No improvement. Counter = 2/15\n",
      "Epoch 21 | Cls: 0.9955 → 0.9370 | Seg: 0.0086 → 0.0649 | Dice: 0.9133\n",
      "  No improvement. Counter = 3/15\n",
      "Epoch 22 | Cls: 0.9960 → 0.9437 | Seg: 0.0085 → 0.0654 | Dice: 0.9131\n",
      "  No improvement. Counter = 4/15\n",
      "Epoch 23 | Cls: 0.9958 → 0.9414 | Seg: 0.0083 → 0.0659 | Dice: 0.9131\n",
      "  No improvement. Counter = 5/15\n",
      "Epoch 24 | Cls: 0.9962 → 0.9354 | Seg: 0.0081 → 0.0671 | Dice: 0.9103\n",
      "  No improvement. Counter = 6/15\n",
      "Epoch 25 | Cls: 0.9970 → 0.9352 | Seg: 0.0079 → 0.0649 | Dice: 0.9160\n",
      "  No improvement. Counter = 7/15\n",
      "Epoch 26 | Cls: 0.9965 → 0.9404 | Seg: 0.0077 → 0.0671 | Dice: 0.9114\n",
      "  No improvement. Counter = 8/15\n",
      "Epoch 27 | Cls: 0.9955 → 0.9440 | Seg: 0.0076 → 0.0681 | Dice: 0.9120\n",
      "  No improvement. Counter = 9/15\n",
      "Epoch 28 | Cls: 0.9970 → 0.9428 | Seg: 0.0074 → 0.0706 | Dice: 0.9073\n",
      "  No improvement. Counter = 10/15\n",
      "Epoch 29 | Cls: 0.9966 → 0.9436 | Seg: 0.0073 → 0.0648 | Dice: 0.9147\n",
      "  No improvement. Counter = 11/15\n",
      "Epoch 30 | Cls: 0.9970 → 0.9429 | Seg: 0.0071 → 0.0656 | Dice: 0.9137\n",
      "  No improvement. Counter = 12/15\n",
      "Epoch 31 | Cls: 0.9972 → 0.9335 | Seg: 0.0070 → 0.0683 | Dice: 0.9098\n",
      "  No improvement. Counter = 13/15\n",
      "Epoch 32 | Cls: 0.9967 → 0.9462 | Seg: 0.0071 → 0.0673 | Dice: 0.9114\n",
      "  New best classification! Val Acc: 0.9462\n",
      "Epoch 33 | Cls: 0.9970 → 0.9489 | Seg: 0.0065 → 0.0681 | Dice: 0.9111\n",
      "  New best classification! Val Acc: 0.9489\n",
      "Epoch 34 | Cls: 0.9964 → 0.9446 | Seg: 0.0065 → 0.0681 | Dice: 0.9106\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 35 | Cls: 0.9973 → 0.9492 | Seg: 0.0065 → 0.0698 | Dice: 0.9078\n",
      "  New best classification! Val Acc: 0.9492\n",
      "Epoch 36 | Cls: 0.9975 → 0.9464 | Seg: 0.0064 → 0.0679 | Dice: 0.9115\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 37 | Cls: 0.9972 → 0.9478 | Seg: 0.0063 → 0.0688 | Dice: 0.9099\n",
      "  No improvement. Counter = 2/15\n",
      "Epoch 38 | Cls: 0.9978 → 0.9459 | Seg: 0.0062 → 0.0673 | Dice: 0.9122\n",
      "  No improvement. Counter = 3/15\n",
      "Epoch 39 | Cls: 0.9972 → 0.9425 | Seg: 0.0061 → 0.0689 | Dice: 0.9104\n",
      "  No improvement. Counter = 4/15\n",
      "Epoch 40 | Cls: 0.9978 → 0.9431 | Seg: 0.0060 → 0.0672 | Dice: 0.9131\n",
      "  No improvement. Counter = 5/15\n",
      "Epoch 41 | Cls: 0.9976 → 0.9435 | Seg: 0.0060 → 0.0660 | Dice: 0.9153\n",
      "  No improvement. Counter = 6/15\n",
      "Epoch 42 | Cls: 0.9978 → 0.9409 | Seg: 0.0059 → 0.0679 | Dice: 0.9122\n",
      "  No improvement. Counter = 7/15\n",
      "Epoch 43 | Cls: 0.9978 → 0.9501 | Seg: 0.0058 → 0.0673 | Dice: 0.9125\n",
      "  New best classification! Val Acc: 0.9501\n",
      "Epoch 44 | Cls: 0.9977 → 0.9474 | Seg: 0.0057 → 0.0686 | Dice: 0.9114\n",
      "  No improvement. Counter = 1/15\n",
      "Epoch 45 | Cls: 0.9974 → 0.9490 | Seg: 0.0056 → 0.0667 | Dice: 0.9134\n",
      "  No improvement. Counter = 2/15\n",
      "Epoch 46 | Cls: 0.9979 → 0.9428 | Seg: 0.0055 → 0.0680 | Dice: 0.9122\n",
      "  No improvement. Counter = 3/15\n",
      "Epoch 47 | Cls: 0.9979 → 0.9460 | Seg: 0.0057 → 0.0706 | Dice: 0.9082\n",
      "  No improvement. Counter = 4/15\n",
      "Epoch 48 | Cls: 0.9982 → 0.9409 | Seg: 0.0054 → 0.0677 | Dice: 0.9142\n",
      "  No improvement. Counter = 5/15\n",
      "Epoch 49 | Cls: 0.9983 → 0.9404 | Seg: 0.0053 → 0.0667 | Dice: 0.9145\n",
      "  No improvement. Counter = 6/15\n",
      "Epoch 50 | Cls: 0.9981 → 0.9444 | Seg: 0.0053 → 0.0691 | Dice: 0.9113\n",
      "  No improvement. Counter = 7/15\n",
      "Epoch 51 | Cls: 0.9982 → 0.9428 | Seg: 0.0052 → 0.0685 | Dice: 0.9118\n",
      "  No improvement. Counter = 8/15\n",
      "Epoch 52 | Cls: 0.9979 → 0.9470 | Seg: 0.0051 → 0.0688 | Dice: 0.9117\n",
      "  No improvement. Counter = 9/15\n",
      "Epoch 53 | Cls: 0.9983 → 0.9455 | Seg: 0.0051 → 0.0677 | Dice: 0.9123\n",
      "  No improvement. Counter = 10/15\n",
      "Epoch 54 | Cls: 0.9981 → 0.9467 | Seg: 0.0051 → 0.0674 | Dice: 0.9130\n",
      "  No improvement. Counter = 11/15\n",
      "Epoch 55 | Cls: 0.9983 → 0.9449 | Seg: 0.0050 → 0.0691 | Dice: 0.9112\n",
      "  No improvement. Counter = 12/15\n",
      "Epoch 56 | Cls: 0.9984 → 0.9489 | Seg: 0.0049 → 0.0686 | Dice: 0.9124\n",
      "  No improvement. Counter = 13/15\n",
      "Epoch 57 | Cls: 0.9982 → 0.9408 | Seg: 0.0049 → 0.0690 | Dice: 0.9121\n",
      "  No improvement. Counter = 14/15\n",
      "Epoch 58 | Cls: 0.9981 → 0.9411 | Seg: 0.0048 → 0.0681 | Dice: 0.9131\n",
      "  No improvement. Counter = 15/15\n",
      "Early stopping!\n",
      "\n",
      "Training complete!\n",
      "Best classification accuracy: 0.9501\n",
      "Best segmentation loss: 0.0597\n",
      "Models saved as 'best_cls_model.pth' and 'best_seg_model.pth'\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0        # best classification accuracy\n",
    "best_seg_loss = float('inf')  # best segmentation loss\n",
    "patience = 15\n",
    "counter = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAINING – Patient-Independent, No Leakage, Real Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    cls_train_loss, cls_train_acc = train_cls_epoch()\n",
    "    cls_val_acc = val_cls_epoch()\n",
    "    seg_train_loss = train_seg_epoch()\n",
    "    seg_val_loss, seg_val_dice = val_seg_epoch()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Cls: {cls_train_acc:.4f} → {cls_val_acc:.4f} | \"\n",
    "          f\"Seg: {seg_train_loss:.4f} → {seg_val_loss:.4f} | \"\n",
    "          f\"Dice: {seg_val_dice:.4f}\")\n",
    "    \n",
    "    improved_cls = False\n",
    "    improved_seg = False\n",
    "    \n",
    "    # Save best classification model\n",
    "    if cls_val_acc > best_val_acc:\n",
    "        best_val_acc = cls_val_acc\n",
    "        torch.save({\n",
    "            'cls_model': cls_model.state_dict(),\n",
    "            'cls_acc': cls_val_acc,\n",
    "            'epoch': epoch\n",
    "        }, \"best_cls_model.pth\")\n",
    "        print(f\"  New best classification! Val Acc: {best_val_acc:.4f}\")\n",
    "        improved_cls = True\n",
    "    \n",
    "    # Save best segmentation model\n",
    "    if seg_val_loss < best_seg_loss:\n",
    "        best_seg_loss = seg_val_loss\n",
    "        torch.save({\n",
    "            'seg_model': seg_model.state_dict(),\n",
    "            'seg_loss': seg_val_loss,\n",
    "            'seg_dice': seg_val_dice,\n",
    "            'epoch': epoch\n",
    "        }, \"best_seg_model.pth\")\n",
    "        print(f\"  New best segmentation! Val Loss: {best_seg_loss:.4f} | Dice: {seg_val_dice:.4f}\")\n",
    "        improved_seg = True\n",
    "    \n",
    "    # Patience logic: increment only if neither improved\n",
    "    if not improved_cls and not improved_seg:\n",
    "        counter += 1\n",
    "        print(f\"  No improvement. Counter = {counter}/{patience}\")\n",
    "    else:\n",
    "        counter = 0\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Best classification accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best segmentation loss: {best_seg_loss:.4f}\")\n",
    "print(\"Models saved as 'best_cls_model.pth' and 'best_seg_model.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
